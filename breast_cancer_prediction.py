# -*- coding: utf-8 -*-
"""breast_cancer_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fRMWnCpfNIcjv97oymDqsyl6WXyeNvpG
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import io
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, accuracy_score
import sklearn.datasets

# try importing tensorflow / keras
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Dropout
    from tensorflow.keras.optimizers import Adam
    TF_AVAILABLE = True
except Exception:
    TF_AVAILABLE = False

# -----------------------
# Helper functions
# -----------------------
@st.cache_data
def load_data():
    ds = sklearn.datasets.load_breast_cancer()
    X = pd.DataFrame(ds.data, columns=ds.feature_names)
    y = pd.Series(ds.target, name='label')
    df = pd.concat([X, y], axis=1)
    return df, ds

@st.cache_resource
def build_model(input_dim, hidden_size=16, lr=0.001):
    if not TF_AVAILABLE:
        raise RuntimeError("TensorFlow / Keras not available in the environment.")
    model = Sequential()
    model.add(Dense(hidden_size, activation='relu', input_shape=(input_dim,)))
    model.add(Dropout(0.2))
    model.add(Dense(hidden_size, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# training returns history and trained model and scaler
def train_model(X_train, y_train, X_val, y_val, params, st_placeholders=None):
    epochs = params['epochs']
    batch_size = params['batch_size']
    hidden = params['hidden']
    lr = params['lr']

    model = build_model(X_train.shape[1], hidden, lr)

    # progress bar in Streamlit
    progress_bar = None
    status_text = None
    if st_placeholders is not None:
        progress_bar = st_placeholders['progress']
        status_text = st_placeholders['status']

    history = {'loss':[], 'val_loss':[], 'accuracy':[], 'val_accuracy':[]}

    for epoch in range(1, epochs+1):
        h = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1,
                      batch_size=batch_size, verbose=0)
        # append metrics
        history['loss'].append(h.history['loss'][0])
        history['val_loss'].append(h.history['val_loss'][0])
        history['accuracy'].append(h.history['accuracy'][0])
        history['val_accuracy'].append(h.history['val_accuracy'][0])

        # update progress
        if progress_bar is not None:
            progress = int(epoch/epochs * 100)
            progress_bar.progress(progress)
            status_text.text(f"Training... Epoch {epoch}/{epochs}")

    if status_text is not None:
        status_text.text(f"Training finished — {epochs} epochs")
    return model, history

# prediction helper
def predict_df(model, scaler, X_raw):
    Xs = scaler.transform(X_raw)
    probs = model.predict(Xs).flatten()
    preds = (probs >= 0.5).astype(int)
    return preds, probs

# -----------------------
# Streamlit UI
# -----------------------
st.set_page_config(page_title="Breast Cancer Classifier", layout="wide")
st.title("🎗️ Breast Cancer Classification — Interactive App")

# Load data
df, ds = load_data()
FEATURES = list(ds.feature_names)

# Tabs
tabs = st.tabs(["📊 Data Explorer", "🧠 Model Training", "🔮 Predict Cancer", "📥 Export"])

# -----------------------
# 1) Data Explorer
# -----------------------
with tabs[0]:
    st.header("Data Explorer")
    st.subheader("Dataset summary")
    c1, c2 = st.columns([2,1])
    with c1:
        st.markdown(f"**Rows:** {df.shape[0]}  —  **Columns:** {df.shape[1]}")
        st.dataframe(df.head(50))
    with c2:
        st.write("Missing values:")
        st.write(df.isnull().sum())

    st.markdown("---")
    st.subheader("Class distribution")
    fig = px.histogram(df, x='label', labels={'label':'Label (0=Malignant,1=Benign)'}, title='Class distribution')
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("Correlation heatmap (select features)")
    selected = st.multiselect("Select features to include in correlation", FEATURES, default=FEATURES[:8])
    if len(selected) >= 2:
        corr = df[selected].corr()
        fig_corr, ax = plt.subplots(figsize=(9,6))
        sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdBu_r', ax=ax)
        st.pyplot(fig_corr)
    else:
        st.info("Please select at least two features to see correlation.")

    st.subheader("Feature distribution")
    feat = st.selectbox("Choose a feature to inspect:", FEATURES)
    fig_hist = px.histogram(df, x=feat, nbins=40, title=f"Histogram of {feat}")
    st.plotly_chart(fig_hist, use_container_width=True)
    fig_box = px.box(df, y=feat, title=f"Boxplot of {feat}")
    st.plotly_chart(fig_box, use_container_width=True)

# -----------------------
# 2) Model Training
# -----------------------
with tabs[1]:
    st.header("Model Training")
    st.markdown("Use the sidebar to select training hyperparameters.")

    with st.sidebar.form(key='train_form'):
        st.subheader("Training hyperparameters")
        epochs = st.slider('Epochs', 1, 50, 10)
        batch_size = st.slider('Batch size', 8, 128, 16)
        hidden = st.number_input('Hidden layer size', min_value=4, max_value=256, value=16, step=4)
        lr = st.slider('Learning rate', 0.0001, 0.1, 0.001, format="%f")
        split = st.slider('Train/Test split (test size)', 0.1, 0.5, 0.2, step=0.05)
        submit = st.form_submit_button('Start Training')

    # place holders for progress
    progress = st.empty()
    status = st.empty()
    st_model_container = st.empty()

    if submit:
        if not TF_AVAILABLE:
            st.error("TensorFlow is not installed in this environment. Training requires TensorFlow/Keras.")
        else:
            # prepare data
            X = df[FEATURES]
            y = df['label']
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42, stratify=y)
            scaler = StandardScaler()
            X_train_s = scaler.fit_transform(X_train)
            X_test_s = scaler.transform(X_test)

            params = {'epochs':epochs, 'batch_size':batch_size, 'hidden':hidden, 'lr':lr}
            placeholders = {'progress': progress.progress(0), 'status': status}

            model, history = train_model(X_train_s, y_train, X_test_s, y_test, params, st_placeholders=placeholders)

            # Evaluate
            preds_test, probs_test = predict_df(model, scaler, X_test)
            acc = accuracy_score(y_test, preds_test)

            st.success(f"Test Accuracy: {acc*100:.2f}%")

            # show charts
            st.subheader("Training curves")
            fig, ax = plt.subplots(1,2, figsize=(12,4))
            ax[0].plot(history['loss'], label='train_loss')
            ax[0].plot(history['val_loss'], label='val_loss')
            ax[0].set_title('Loss')
            ax[0].legend()
            ax[1].plot(history['accuracy'], label='train_acc')
            ax[1].plot(history['val_accuracy'], label='val_acc')
            ax[1].set_title('Accuracy')
            ax[1].legend()
            st.pyplot(fig)

            # confusion matrix
            st.subheader('Confusion matrix')
            cm = confusion_matrix(y_test, preds_test)
            fig_cm, ax = plt.subplots()
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_xlabel('Predicted')
            ax.set_ylabel('Actual')
            st.pyplot(fig_cm)

            # Save model & scaler to session_state for later prediction/export
            st.session_state['trained_model'] = model
            st.session_state['scaler'] = scaler
            st.session_state['last_score'] = acc
            st.session_state['features'] = FEATURES
            st.info('Model saved in session. Use the Predict tab to try sample inputs.')

    else:
        st.info('Adjust hyperparameters in the sidebar and click Start Training.')

    # Option to download model
    if 'trained_model' in st.session_state:
        st.markdown('---')
        save_col1, save_col2 = st.columns(2)
        with save_col1:
            if st.button('Download trained model (pickle)'):
                # pickle model and scaler
                model = st.session_state['trained_model']
                scaler = st.session_state['scaler']
                bio = io.BytesIO()
                try:
                    pickle.dump({'model': model, 'scaler': scaler}, bio)
                    bio.seek(0)
                    st.download_button('Download .pkl', data=bio, file_name='breast_cancer_model.pkl')
                except Exception as e:
                    st.error('Could not pickle model in this environment: ' + str(e))
        with save_col2:
            uploaded = st.file_uploader('Upload a .pkl model to load (model+scaler dict)', type=['pkl','pickle'])
            if uploaded is not None:
                try:
                    content = pickle.load(uploaded)
                    st.session_state['trained_model'] = content['model']
                    st.session_state['scaler'] = content['scaler']
                    st.success('Model loaded into session.')
                except Exception as e:
                    st.error('Could not load model: ' + str(e))

# -----------------------
# 3) Predict Cancer
# -----------------------
with tabs[2]:
    st.header('Predict Cancer')
    st.write('Use an uploaded CSV or enter manual values to get predictions.')

    mode = st.radio('Prediction mode', ['Upload CSV', 'Manual input'])

    if mode == 'Upload CSV':
        uploaded = st.file_uploader('Upload CSV with feature columns', type=['csv'])
        if uploaded is not None:
            df_in = pd.read_csv(uploaded)
            st.dataframe(df_in.head())
            if 'trained_model' not in st.session_state:
                st.warning('No trained model in session. Train or upload a trained model first.')
            else:
                model = st.session_state['trained_model']
                scaler = st.session_state['scaler']
                # ensure correct columns
                cols = st.session_state.get('features', FEATURES)
                missing = [c for c in cols if c not in df_in.columns]
                if missing:
                    st.error('Uploaded CSV missing these required columns: ' + ', '.join(missing))
                else:
                    preds, probs = predict_df(model, scaler, df_in[cols])
                    out = df_in.copy()
                    out['pred'] = preds
                    out['probability'] = probs
                    st.dataframe(out.head())
                    st.session_state['last_predictions'] = out

    else:
        st.subheader('Manual input')
        st.write('You can load a sample from the dataset to edit, or create a custom input.')
        sample_idx = st.number_input('Sample index (0..n-1) - leave blank to create from zeros', min_value=0, max_value=len(df)-1, value=0)
        base = st.checkbox('Load sample values as starting point', value=True)

        manual_vals = {}
        if base:
            sample = df.loc[int(sample_idx), FEATURES]
            for f in FEATURES:
                manual_vals[f] = st.number_input(f, value=float(sample[f]))
        else:
            for f in FEATURES:
                manual_vals[f] = st.number_input(f, value=0.0)

        if st.button('Predict this input'):
            if 'trained_model' not in st.session_state:
                st.error('No trained model in session. Train or upload a model first.')
            else:
                model = st.session_state['trained_model']
                scaler = st.session_state['scaler']
                Xraw = pd.DataFrame([manual_vals])
                pred, prob = predict_df(model, scaler, Xraw)
                label = '✅ Benign' if pred[0]==1 else '⚠️ Malignant'
                st.metric('Prediction', label, delta=f"Probability: {prob[0]*100:.2f}%")
                # feature importance / simple explanation
                st.subheader('Simple feature effect')
                st.write('Showing feature values for this input:')
                st.dataframe(Xraw.T)

                # Try SHAP if available
                try:
                    import shap
                    explainer = shap.KernelExplainer(model.predict, scaler.transform(df[FEATURES].iloc[:100]))
                    shap_values = explainer.shap_values(scaler.transform(Xraw))
                    st.subheader('SHAP explanation (approx)')
                    shap.force_plot(explainer.expected_value, shap_values, Xraw, matplotlib=True, show=False)
                    st.pyplot(plt.gcf())
                except Exception:
                    st.info('SHAP not available — showing simple top features by difference from mean')
                    diffs = (Xraw.iloc[0] - df[FEATURES].mean()).abs().sort_values(ascending=False).head(8)
                    fig = px.bar(x=diffs.index, y=diffs.values, labels={'x':'feature','y':'abs diff from mean'}, title='Top feature differences from population mean')
                    st.plotly_chart(fig)

# -----------------------
# 4) Export
# -----------------------
with tabs[3]:
    st.header('Export')
    st.write('Download predictions created in Predict tab, reset session, or clear stored model.')

    if 'last_predictions' in st.session_state:
        out = st.session_state['last_predictions']
        csv = out.to_csv(index=False).encode('utf-8')
        st.download_button('Download last predictions CSV', data=csv, file_name='predictions.csv', mime='text/csv')
    else:
        st.info('No predictions in session yet.')

    if st.button('Clear session (remove model & predictions)'):
        keys = ['trained_model','scaler','last_predictions','last_score']
        for k in keys:
            if k in st.session_state:
                del st.session_state[k]
        st.success('Session cleared.')

    st.markdown('---')
    st.write('You can also copy the app Python file and run:')
    st.code('streamlit run streamlit_breast_cancer_app.py')

!pip install streamlit